A distribution summary is used to track the distribution of events. It is similar to a timer structurally, but records values that do not represent a unit of time. For example, a distribution summary could be used to measure the payload sizes of requests hitting a server.

To create a distribution summary:

[source, java]
----
DistributionSummary summary = registry.summary("response.size");
----

The interface contains a fluent builder for distribution summaries:

[source, java]
----
DistributionSummary summary = DistributionSummary
    .builder("response.size")
    .description("a description of what this summary does") // optional
    .baseUnit("bytes") // optional <1>
    .tags("region", "test") // optional
    .scale(100) // optional <2>
    .register(registry);
----

1. Add base units for maximum portability -- base units are part of the naming convention for some monitoring systems. Leaving it off and violating the naming convention will have no adverse effect if you forget.
2. Optionally, you may provide a scaling factor that each recorded sample will be multipled by as it is recorded.

== Scaling and histograms

Micrometer's preselected percentile histogram buckets are all integers from 1 to maximum long. Currently `minimumExpectedValue` and `maximumExpectedValue` serve to control the cardinality of the bucket set. If we attempt to detect that your min/max yields a small range and scale the preselected bucket domain to your summary's range, then we don't have another lever to control bucket cardinality.

Instead, if your summary's domain is more constrained, scale your summary's range by a fixed factor. The use case we've heard so far is for summaries of ratios whose domain is [0,1]. Then:

[source,java]
----
DistributionSummary.builder("my.ratio").scale(100).register(registry)
----

This way, the ratio winds up in the range [0,100] and we can set `maximumExpectedValue` to 100. Pair this with custom SLA boundaries if you care about particular ratios:

[source,java]
----
DistributionSummary.builder("my.ratio")
   .scale(100)
   .sla(70, 80, 90)
   .register(registry)
----


== Memory footprint estimation

The total memory footprint of a distribution summary can vary dramatically depending on which options you choose. Below is a table of memory consumption based on the use of various features. These figures assume no tags and a ring buffer length of 3. Adding tags of course adds somewhat to the total, as does increasing the buffer length. Total storage can also vary somewhat depending on the registry implementation.

* R = Ring buffer length. We assume the default of 3 in all examples. R is set with `DistributionSummary.Builder#distributionStatisticBufferLength`.
* B = Total histogram buckets. Can be SLA boundaries or percentile histogram buckets. By default, summaries have NO minimum and maximum expected value, so ship all 276 predetermined histogram buckets. You should always clamp distribution summaries with a `minimumExpectedValue` and `maximumExpectedValue` when you intend to ship percentile histograms.
* M = Time-decaying max. 104 bytes
* Fb = Fixed boundary histogram. 30b * B * R
* Pp = Percentile precision. By default is 1. Generally in the range [0, 3]. Pp is set with `DistributionSummary.Builder#percentilePrecision`.
* Hdr(Pp) = High dynamic range histogram.
  - When Pp = 0: 1.9kb * R + 0.8kb
  - When Pp = 1: 3.8kb * R + 1.1kb
  - When Pp = 2: 18.2kb * R + 4.7kb
  - When Pp = 3: 66kb * R + 33kb


[width="80%",options="header"]
|=========================================================
|Client-side percentiles |Histogram and/or SLAs |Formula | Example

|No  |No  |M| ~0.1kb
|No  |Yes |M + Fb|For percentile histogram clamped to 66 buckets, ~6kb
|Yes |Yes |M + Hdr(Pp)|For the addition of a 0.95 percentile with defaults otherwise, ~12.6kb
|=========================================================

NOTE: These estimations are based on improvements made in Micrometer 1.0.3, and assume at least that version.

NOTE: For Prometheus specifically, R is _always_ equal to 1, regardless of how you attempt to configure it through `DistributionSummary.Builder`. This is special-cased for Prometheus because it expects cumulative histogram data that never rolls over.
